{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/media/data/studia/sieci_neuronowe_7_sem')\n",
    "from nn.metrics import accuracy\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from nn.init import init_weights\n",
    "from nn.layers.activations import ReLU, Tanh, Sigmoid\n",
    "from nn.layers.linear import Linear\n",
    "from nn.layers.model import Model\n",
    "from nn.loss import cross_entropy\n",
    "from nn.optimization import sgd\n",
    "from nn.training import Trainer, DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = MNIST('./data', train=True, download=True)\n",
    "x_train = dataset.data.numpy()\n",
    "x_train = x_train\n",
    "y_train = dataset.targets.numpy()\n",
    "\n",
    "dataset = MNIST('./data', train=False, download=True)\n",
    "x_test = dataset.data.numpy()\n",
    "y_test = dataset.targets.numpy()\n",
    "\n",
    "def preprocess_x(x):\n",
    "    return x.reshape(-1, 784) / 255.\n",
    "\n",
    "train_set = list(zip(preprocess_x(x_train), y_train))\n",
    "test_set = list(zip(preprocess_x(x_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Loss: 0.7536, Patience: 30: : 469it [00:18, 26.01it/s]\nLoss: 0.8102, Patience: 30:  17%|█▋        | 78/468 [00:03&lt;00:18, 20.90it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m&lt;ipython-input-6-9a8cc61d6eec&gt;\u001B[0m in \u001B[0;36m&lt;module&gt;\u001B[0;34m\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0mtest_generator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataGenerator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_generator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_generator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 34\u001B[0;31m \u001B[0mexperiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactivation_func\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mTanh\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m&lt;ipython-input-6-9a8cc61d6eec&gt;\u001B[0m in \u001B[0;36minner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----&gt; 6\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m         \u001B[0mstop\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m&lt;ipython-input-6-9a8cc61d6eec&gt;\u001B[0m in \u001B[0;36mexperiment\u001B[0;34m(hidden_size, learning_rate, batch_size, std, activation_func)\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[0mtrain_generator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataGenerator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0mtest_generator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataGenerator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 33\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_generator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_generator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m \u001B[0mexperiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactivation_func\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mTanh\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/media/data/studia/sieci_neuronowe_7_sem/nn/training.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, model, train_generator, validation_generator)\u001B[0m\n\u001B[1;32m     27\u001B[0m                 \u001B[0mlogits\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaches\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m                 \u001B[0mloss_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_loss_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 29\u001B[0;31m                 \u001B[0mgrads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss_grad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_optimizer_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/media/data/studia/sieci_neuronowe_7_sem/nn/layers/model.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, upstream_grads, cache)\u001B[0m\n\u001B[1;32m     19\u001B[0m             \u001B[0mlayer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_layers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m             \u001B[0mcache\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcaches\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 21\u001B[0;31m             \u001B[0mupstream_grads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mupstream_grads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcache\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m             \u001B[0mgrads\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/media/data/studia/sieci_neuronowe_7_sem/nn/layers/linear.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, grads, cache)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcache\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 16\u001B[0;31m         \u001B[0md_downsream\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrads\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_weight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m         \u001B[0md_weight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcache\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m&#39;x&#39;\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0md_bias\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrads\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "def time_it(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        start = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        stop = time()\n",
    "        return result, stop - start\n",
    "    return inner\n",
    "\n",
    "@time_it\n",
    "def experiment(hidden_size=256, learning_rate=0.001, batch_size=128, std=0.05, activation_func=ReLU):\n",
    "    model = Model(\n",
    "        Linear(784, hidden_size, init_func=partial(init_weights, std=std)),\n",
    "        activation_func(),\n",
    "        Linear(hidden_size, 10),\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        optimizer_func=partial(sgd, learning_rate=1e-3),\n",
    "        loss_func=cross_entropy,\n",
    "        epochs=30,\n",
    "        metrics={'accuracy': accuracy},\n",
    "        monitor='accuracy',\n",
    "        mode='max',\n",
    "        delta=0.00,\n",
    "        patience=30,\n",
    "\n",
    "    )\n",
    "\n",
    "    train_generator = DataGenerator(train_set, batch_size=batch_size)\n",
    "    test_generator = DataGenerator(test_set, batch_size=128)\n",
    "    return list(trainer.train(model, train_generator, test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Loss: 2.393, Patience: 30:   1%|          | 4/468 [00:00&lt;00:12, 37.00it/s]hidden_size: 16\n\nLoss: 2.082, Patience: 30: : 469it [00:07, 65.24it/s]                       \nLoss: 1.951, Patience: 30: : 469it [00:07, 61.42it/s]                       \nLoss: 1.824, Patience: 30: : 469it [00:06, 74.36it/s]                       \nLoss: 1.679, Patience: 30: : 469it [00:09, 51.93it/s]                       \nLoss: 1.5, Patience: 30: : 469it [00:06, 70.72it/s]\nLoss: 1.337, Patience: 30: : 469it [00:04, 100.62it/s]                       \nLoss: 1.274, Patience: 30: : 469it [00:09, 51.93it/s]                       \nLoss: 1.07, Patience: 30: : 469it [00:08, 56.02it/s]                       \nLoss: 1.014, Patience: 30: : 469it [00:09, 51.88it/s]                       \nLoss: 0.9552, Patience: 30: : 469it [00:10, 46.77it/s]                       \nLoss: 0.7831, Patience: 30: : 469it [00:08, 52.77it/s]\nLoss: 0.7528, Patience: 30: : 469it [00:09, 51.14it/s]                       \nLoss: 0.9143, Patience: 30: : 469it [00:09, 52.01it/s]                       \nLoss: 0.7409, Patience: 30: : 469it [00:09, 48.20it/s]                       \nLoss: 0.6621, Patience: 30: : 469it [00:08, 54.99it/s]                       \nLoss: 0.6216, Patience: 30: : 469it [00:09, 49.64it/s]                       \nLoss: 0.6287, Patience: 30: : 469it [00:08, 52.49it/s]\nLoss: 0.7002, Patience: 30: : 469it [00:09, 50.35it/s]\nLoss: 0.5891, Patience: 30: : 469it [00:09, 46.98it/s]                       \nLoss: 0.5495, Patience: 30: : 469it [00:09, 50.30it/s]                       \nLoss: 0.633, Patience: 30: : 469it [00:07, 61.74it/s]                       \nLoss: 0.5198, Patience: 30: : 469it [00:07, 63.37it/s]                       \nLoss: 0.6585, Patience: 30: : 469it [00:07, 61.26it/s]                       \nLoss: 0.5194, Patience: 30: : 469it [00:08, 56.12it/s]                       \nLoss: 0.4855, Patience: 30: : 469it [00:08, 52.85it/s]                       \nLoss: 0.5369, Patience: 30: : 469it [00:08, 57.40it/s]                       \nLoss: 0.6241, Patience: 30: : 469it [00:08, 56.96it/s]                       \nLoss: 0.5318, Patience: 30: : 469it [00:05, 79.01it/s]                       \nLoss: 0.5483, Patience: 30: : 469it [00:05, 83.62it/s]                        \nLoss: 0.4763, Patience: 30: : 469it [00:05, 78.93it/s]                       \nLoss: 2.353, Patience: 30:   1%|          | 3/468 [00:00&lt;00:16, 28.14it/s]Best validation accuracy: 0.8811\n\nhidden_size: 64\n\nLoss: 1.737, Patience: 30: : 469it [00:05, 79.82it/s]                        \nLoss: 1.307, Patience: 30: : 469it [00:05, 83.48it/s]                       \nLoss: 1.13, Patience: 30: : 469it [00:06, 76.60it/s]                       \nLoss: 0.7611, Patience: 30: : 469it [00:08, 55.88it/s]                       \nLoss: 0.7492, Patience: 30: : 469it [00:08, 55.62it/s]                       \nLoss: 0.7344, Patience: 30: : 469it [00:08, 52.24it/s]                       \nLoss: 0.6412, Patience: 30: : 469it [00:07, 59.87it/s]                       \nLoss: 0.6005, Patience: 30: : 469it [00:08, 56.96it/s]                       \nLoss: 0.5322, Patience: 30: : 469it [00:07, 65.14it/s]                       \nLoss: 0.5004, Patience: 30: : 469it [00:08, 55.02it/s]                       \nLoss: 0.504, Patience: 30: : 469it [00:07, 62.46it/s]                       \nLoss: 0.4238, Patience: 30: : 469it [00:07, 61.56it/s]                       \nLoss: 0.4258, Patience: 30: : 469it [00:07, 60.00it/s]                       \nLoss: 0.48, Patience: 30: : 469it [00:07, 61.60it/s]                       \nLoss: 0.5264, Patience: 30: : 469it [00:07, 62.44it/s]                       \nLoss: 0.397, Patience: 30: : 469it [00:07, 66.08it/s]                       \nLoss: 0.5351, Patience: 30: : 469it [00:06, 69.01it/s]                       \nLoss: 0.3215, Patience: 30: : 469it [00:07, 65.48it/s]                       \nLoss: 0.4051, Patience: 30: : 469it [00:07, 64.44it/s]                       \nLoss: 0.4965, Patience: 30: : 469it [00:07, 59.34it/s]                       \nLoss: 0.4221, Patience: 30: : 469it [00:07, 63.13it/s]                       \nLoss: 0.3741, Patience: 30: : 469it [00:06, 73.30it/s]\nLoss: 0.3243, Patience: 30: : 469it [00:07, 62.38it/s]                       \nLoss: 0.3704, Patience: 30: : 469it [00:07, 66.69it/s]                       \nLoss: 0.4021, Patience: 30: : 469it [00:07, 61.05it/s]                       \nLoss: 0.359, Patience: 30: : 469it [00:06, 68.86it/s]                       \nLoss: 0.3545, Patience: 30: : 469it [00:07, 62.48it/s]                       \nLoss: 0.2515, Patience: 30: : 469it [00:07, 59.21it/s]\nLoss: 0.3951, Patience: 30: : 469it [00:07, 66.70it/s]                       \nLoss: 0.4793, Patience: 30: : 469it [00:07, 61.34it/s]                       \nLoss: 2.923, Patience: 30:   1%|          | 3/468 [00:00&lt;00:17, 26.39it/s]Best validation accuracy: 0.9015\n\nhidden_size: 128\n\nLoss: 1.177, Patience: 30: : 469it [00:08, 52.81it/s]                       \nLoss: 0.9444, Patience: 30: : 469it [00:09, 48.89it/s]                       \nLoss: 0.6425, Patience: 30: : 469it [00:09, 49.53it/s]\nLoss: 0.7596, Patience: 30: : 469it [00:09, 49.09it/s]                       \nLoss: 0.5515, Patience: 30: : 469it [00:09, 50.74it/s]                       \nLoss: 0.4609, Patience: 30: : 469it [00:09, 51.12it/s]                       \nLoss: 0.5659, Patience: 30: : 469it [00:11, 41.01it/s]                       \nLoss: 0.5199, Patience: 30: : 469it [00:10, 45.35it/s]                       \nLoss: 0.3943, Patience: 30: : 469it [00:09, 51.49it/s]                       \nLoss: 0.4515, Patience: 30: : 469it [00:09, 51.37it/s]                       \nLoss: 0.2449, Patience: 30: : 469it [00:09, 48.43it/s]                       \nLoss: 0.4997, Patience: 30: : 469it [00:09, 50.74it/s]                       \nLoss: 0.3921, Patience: 30: : 469it [00:10, 45.67it/s]\nLoss: 0.3735, Patience: 30: : 469it [00:09, 49.69it/s]\nLoss: 0.2795, Patience: 30: : 469it [00:09, 50.60it/s]                       \nLoss: 0.4155, Patience: 30: : 469it [00:08, 54.61it/s]                       \nLoss: 0.2595, Patience: 30: : 469it [00:09, 50.44it/s]                       \nLoss: 0.344, Patience: 30: : 469it [00:09, 50.16it/s]                       \nLoss: 0.2949, Patience: 30: : 469it [00:09, 51.58it/s]\nLoss: 0.2914, Patience: 30: : 469it [00:09, 48.38it/s]                       \nLoss: 0.2589, Patience: 30: : 469it [00:09, 51.19it/s]                       \nLoss: 0.4624, Patience: 30: : 469it [00:09, 48.49it/s]                       \nLoss: 0.2668, Patience: 30: : 469it [00:09, 51.41it/s]                       \nLoss: 0.1221, Patience: 30: : 469it [00:08, 52.33it/s]                       \nLoss: 0.3698, Patience: 30: : 469it [00:09, 49.21it/s]                       \nLoss: 0.3324, Patience: 30: : 469it [00:09, 49.90it/s]                       \nLoss: 0.2457, Patience: 30: : 469it [00:09, 48.92it/s]\nLoss: 0.2376, Patience: 30: : 469it [00:09, 50.58it/s]\nLoss: 0.4771, Patience: 30: : 469it [00:09, 51.15it/s]                       \nLoss: 0.2794, Patience: 30: : 469it [00:08, 52.18it/s]                       \nLoss: 3.326, Patience: 30:   0%|          | 0/468 [00:00&lt;?, ?it/s]Best validation accuracy: 0.9202\n\nhidden_size: 256\n\nLoss: 0.7438, Patience: 30: : 469it [00:12, 36.61it/s]                       \nLoss: 0.5936, Patience: 30: : 469it [00:13, 36.00it/s]                       \nLoss: 0.7176, Patience: 30: : 469it [00:13, 35.31it/s]\nLoss: 0.7731, Patience: 30: : 469it [00:13, 33.56it/s]                       \nLoss: 0.4364, Patience: 30: : 469it [00:13, 34.34it/s]                       \nLoss: 0.4244, Patience: 30: : 469it [00:12, 37.02it/s]\nLoss: 0.4397, Patience: 30: : 469it [00:12, 36.79it/s]\nLoss: 0.3798, Patience: 30: : 469it [00:13, 33.80it/s]                       \nLoss: 0.3963, Patience: 30: : 469it [00:12, 36.68it/s]                       \nLoss: 0.3708, Patience: 30: : 469it [00:13, 34.72it/s]\nLoss: 0.5228, Patience: 30: : 469it [00:13, 34.59it/s]                       \nLoss: 0.3684, Patience: 30: : 469it [00:13, 35.75it/s]                       \nLoss: 0.2584, Patience: 30: : 469it [00:11, 39.17it/s]                       \nLoss: 0.375, Patience: 30: : 469it [00:11, 39.22it/s]                       \nLoss: 0.2476, Patience: 30: : 469it [00:11, 41.35it/s]\nLoss: 0.4478, Patience: 30: : 469it [00:15, 31.06it/s]\nLoss: 0.3411, Patience: 30: : 469it [00:14, 32.28it/s]                       \nLoss: 0.2372, Patience: 30: : 469it [00:17, 27.18it/s]                       \nLoss: 0.2991, Patience: 30: : 469it [00:07, 60.48it/s]                       \nLoss: 0.3555, Patience: 30: : 469it [00:16, 27.66it/s]\nLoss: 0.2958, Patience: 30: : 469it [00:15, 30.83it/s]                       \nLoss: 0.2792, Patience: 30: : 469it [00:13, 33.87it/s]                       \nLoss: 0.3341, Patience: 30: : 469it [00:13, 34.31it/s]                       \nLoss: 0.2012, Patience: 30: : 469it [00:14, 33.14it/s]\nLoss: 0.4012, Patience: 30: : 469it [00:14, 32.44it/s]\nLoss: 0.3283, Patience: 30: : 469it [00:13, 34.70it/s]\nLoss: 0.2123, Patience: 30: : 469it [00:13, 33.87it/s]                       \nLoss: 0.2492, Patience: 30: : 469it [00:13, 33.89it/s]                       \nLoss: 0.2452, Patience: 30: : 469it [00:13, 33.70it/s]\nLoss: 0.2413, Patience: 30: : 469it [00:14, 33.48it/s]\nLoss: 4.645, Patience: 30:   0%|          | 0/468 [00:00&lt;?, ?it/s]Best validation accuracy: 0.9289\n\nhidden_size: 1024\n\nLoss: 0.8308, Patience: 30:  60%|██████    | 281/468 [00:21&lt;00:14, 12.89it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m&lt;ipython-input-13-233ebeeb3f4f&gt;\u001B[0m in \u001B[0;36m&lt;module&gt;\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf&#39;{arg}: {value}\\n&#39;\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0mresult\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 16\u001B[0;31m         \u001B[0mmetrics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexperiment_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexperiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m         \u001B[0mresult\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m&#39;value&#39;\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0mresult\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m&#39;time&#39;\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexperiment_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m&lt;ipython-input-11-1233ac042420&gt;\u001B[0m in \u001B[0;36minner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----&gt; 6\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m         \u001B[0mstop\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m&lt;ipython-input-11-1233ac042420&gt;\u001B[0m in \u001B[0;36mexperiment\u001B[0;34m(hidden_size, learning_rate, batch_size, std, activation_func)\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[0mtrain_generator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataGenerator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0mtest_generator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataGenerator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 33\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_generator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_generator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/media/data/studia/sieci_neuronowe_7_sem/nn/training.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, model, train_generator, validation_generator)\u001B[0m\n\u001B[1;32m     27\u001B[0m                 \u001B[0mlogits\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaches\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m                 \u001B[0mloss_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_loss_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 29\u001B[0;31m                 \u001B[0mgrads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss_grad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_optimizer_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/media/data/studia/sieci_neuronowe_7_sem/nn/layers/model.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, upstream_grads, cache)\u001B[0m\n\u001B[1;32m     19\u001B[0m             \u001B[0mlayer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_layers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m             \u001B[0mcache\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcaches\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 21\u001B[0;31m             \u001B[0mupstream_grads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mupstream_grads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcache\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m             \u001B[0mgrads\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/media/data/studia/sieci_neuronowe_7_sem/nn/layers/linear.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, grads, cache)\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcache\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0md_downsream\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrads\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_weight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---&gt; 17\u001B[0;31m         \u001B[0md_weight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcache\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m&#39;x&#39;\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m         \u001B[0md_bias\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrads\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0md_downsream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m&#39;_weight&#39;\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0md_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m&#39;_bias&#39;\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0md_bias\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "experiment_specs = {\n",
    "    'hidden_size': [16, 64, 128, 256, 1024],\n",
    "    'learning_rate': [1e-5, 1e-4, 1e-3, 1e-1],\n",
    "    'batch_size': [1, 64, 128, 256, 512],\n",
    "    'std': [0.0001, 0.1, 0.3, 0.8],\n",
    "    'activation_func': [ReLU, Tanh, Sigmoid]\n",
    "}\n",
    "\n",
    "result_path = Path('./result.json')\n",
    "result = {}\n",
    "for arg, values in experiment_specs.items():\n",
    "    result[arg] = {}\n",
    "    for value in values:\n",
    "        print(f'{arg}: {value}\\n')\n",
    "        result[arg][str(value)] = {}\n",
    "        metrics, experiment_time = experiment(**{arg: value})\n",
    "        result[arg][str(value)]['value'] = metrics\n",
    "        result[arg][str(value)]['time'] = experiment_time\n",
    "\n",
    "        print(f'Best validation accuracy: {max(a[\"accuracy\"] for _, a in metrics):.4}\\n')\n",
    "\n",
    "        with result_path.open('w') as file:\n",
    "            json.dump(result, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.00903136, -0.07781877,  0.03398565, ...,  0.05009631,\n         0.07205296, -0.02185572],\n       [ 0.04742982, -0.01818698, -0.02515133, ..., -0.01136244,\n        -0.01199874, -0.00294767],\n       [-0.03188821,  0.05495292, -0.00668778, ..., -0.02476683,\n         0.00990076, -0.07795491],\n       ...,\n       [ 0.11051129, -0.05569008,  0.04533202, ...,  0.04103275,\n         0.04337337, -0.0471332 ],\n       [-0.01428359,  0.03714409, -0.03014214, ..., -0.01259957,\n        -0.03742836, -0.01441736],\n       [-0.07751212, -0.05631129, -0.07758386, ..., -0.00286561,\n        -0.04752837,  0.01186537]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}